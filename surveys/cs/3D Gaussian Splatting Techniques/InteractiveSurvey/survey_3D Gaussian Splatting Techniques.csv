sentence,references
"The field of 3D scene reconstruction and novel view synthesis has seen significant advancements in recent years, driven by the increasing demand for realistic and interactive 3D content in applications such as virtual reality (VR), augmented reality (AR), and computer graphics [1]",[1] You Need a Transition Plane  Bridging Continuous Panoramic 3D  Reconstruction with Perspective Gauss
"The advent of 3D Gaussian Splatting (3DGS) has emerged as a promising alternative, offering a balance between computational efficiency and high-fidelity representation [2]. 3DGS represents 3D scenes using a collection of Gaussian primitives, each defined by parameters such as position, scale, rotation, and opacity [3]",[2] View-Dependent Uncertainty Estimation of 3D Gaussian Splatting;[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"This survey paper focuses on the recent advancements in 3D Gaussian Splatting techniques, particularly in the areas of semantic optimization, feature propagation, deformation, and uncertainty estimation [4]",[4] Training-Free Hierarchical Scene Understanding for Gaussian Splatting  with Superpoint Graphs
"The paper aims to provide a comprehensive overview of the latest research, highlighting the key techniques and methodologies that have contributed to the evolution of 3DGS [5]",[5] ARAP-GS  Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing  with Diffusion Prior
"We begin by exploring enhancements in semantic optimization and feature propagation, which are crucial for improving the accuracy and robustness of 3D scene representations [6]",[6] GSFF-SLAM  3D Semantic Gaussian Splatting SLAM via Feature Field
"Cage-based deformation, ARAP deformation with a diffusion prior, and NeuralCage Learning are examined, showcasing their contributions to structure-aware and automated 3D scene manipulation [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"The paper also covers advancements in uncertainty and efficiency improvements, which are vital for enhancing the reliability and practicality of 3DGS models [2]",[2] View-Dependent Uncertainty Estimation of 3D Gaussian Splatting
"Finally, the survey explores advanced 3D scene representation and inpainting techniques, including Gaussian-Enhanced Surfels, opacity modulation, and hash grids for fast rendering [8]",[8] Visibility-Uncertainty-guided 3D Gaussian Inpainting via Scene  Conceptional Learning
"The paper concludes by discussing future directions and potential areas for further research, emphasizing the ongoing need for innovation in 3D scene reconstruction and novel view synthesis [9]",[9] DropoutGS  Dropping Out Gaussians for Better Sparse-view Rendering
"Firstly, it provides a comprehensive and structured overview of the latest advancements in 3D Gaussian Splatting techniques, synthesizing insights from a wide range of research papers and studies [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"By consolidating the current state of the art, this survey aims to inspire further innovations and advancements in 3D Gaussian Splatting techniques [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
Decoupled Semantic Optimization (DSO) is a novel approach designed to enhance the efficiency and accuracy of semantic reconstruction in 3D Gaussian Splatting (3DGS) frameworks [4],[4] Training-Free Hierarchical Scene Understanding for Gaussian Splatting  with Superpoint Graphs
"This decoupling is achieved by first reconstructing the geometric representation of the scene to a high level of detail, followed by an independent optimization step that focuses on refining the semantic embeddings [6]",[6] GSFF-SLAM  3D Semantic Gaussian Splatting SLAM via Feature Field
"Extensive experiments on various datasets and 3DGS frameworks have shown that DSO consistently improves rendering quality and reduces model storage, making it a valuable addition to the toolkit of 3D scene reconstruction methods [10]",[10] EDGS  Eliminating Densification for Efficient Convergence of 3DGS
Contextual Feature Propagation (CFP) is a critical component in enhancing the accuracy and robustness of 3D Gaussian Splatting (3DGS) by addressing the issue of cross-view granularity inconsistency [11],[11] CAGS  Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian  Splatting
"Traditional 3DGS methods often struggle with maintaining consistent feature granularity across different views, leading to fragmented and noisy 3D object representations [12]",[12] VGNC  Reducing the Overfitting of Sparse-view 3DGS via Validation-guided  Gaussian Number Control
Mask-Aware Contrastive Learning (MA-CL) is a novel approach designed to address the challenges of cross-view granularity inconsistency in 3D Gaussian Splatting (3DGS) [11],[11] CAGS  Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian  Splatting
"Unlike traditional methods that rely on per-pixel InfoNCE losses, which are susceptible to granularity noise, MA-CL computes feature centroids within segmentation masks derived from the Segment Anything Model (SAM) and applies contrastive supervision to these centroids across different views [11]",[11] CAGS  Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian  Splatting
This approach not only stabilizes the training process but also improves the quality of the reconstructed 3D scenes [13],[13] HUG  Hierarchical Urban Gaussian Splatting with Block-Based  Reconstruction
"Overall, MA-CL represents a significant advancement in 3DGS by addressing key challenges in cross-view consistency and computational efficiency, making it a valuable tool for high-quality 3D scene reconstruction and novel view synthesis [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
Cage-based deformation is a powerful technique in computer graphics that facilitates intuitive and structure-aware manipulation of 3D models while preserving fine details [7],[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"Unlike direct vertex-based deformation, which can result in unstructured distortions, a cage provides a high-level control structure that smoothly influences the deformation of the enclosed model [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"However, these methods are not directly applicable to the complexity and discreteness of 3D Gaussian Splatting (3DGS) [14]",[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
"To address the limitations of traditional cage-based deformation methods in the context of 3DGS, we introduce a novel cage-based 3DGS deformation technique [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"This approach ensures that the deformation is smooth and coherent, maintaining the fine details of the original 3DGS representation [5]",[5] ARAP-GS  Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing  with Diffusion Prior
"Experimental results demonstrate that our method significantly improves the quality and efficiency of 3DGS deformations, making it a valuable tool for a wide range of applications, from virtual reality and augmented reality to 3D content creation and simulation [15]",[15] AAA-Gaussians  Anti-Aliased and Artifact-Free 3D Gaussian Rendering
"ARAP-GS, an innovative method for 3D Gaussian Splatting (3DGS) editing, leverages As-Rigid-As-Possible (ARAP) deformation combined with a diffusion prior to achieve intuitive and high-quality 3DGS manipulation [5]",[5] ARAP-GS  Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing  with Diffusion Prior
"The method is designed to enable users to perform free-form deformations on 3DGS models using simple drag operations, while maintaining the structural integrity and visual fidelity of the scene [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"The process begins with transforming the initial 3D Gaussians into a representative subset, which is then deformed according to the user's input [15]",[15] AAA-Gaussians  Anti-Aliased and Artifact-Free 3D Gaussian Rendering
"This iterative optimization process ensures that the final 3DGS model not only maintains the intended deformation but also preserves the fine details and textures, leading to a more realistic and visually coherent result [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"NeuralCage Learning represents a significant advancement in the field of 3D scene deformation, addressing the limitations of traditional cage-based methods that often require manual manipulation of cage vertices [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"Our proposed method, CAGE-GS, integrates NeuralCage Learning with 3D Gaussian Splatting (3DGS) to create a cage-based 3DGS deformation framework [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"This integration allows for the automatic geometric transfer from a target model to a 3DGS representation, ensuring that the deformation is both structurally coherent and visually consistent [5]",[5] ARAP-GS  Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing  with Diffusion Prior
"CAGE-GS leverages the structured deformation space provided by NeuralCage Learning to optimize the parameters of the 3D Gaussians, resulting in high-fidelity texture preservation and smooth surface transitions [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"This approach not only simplifies the deformation process but also enhances the quality of the deformed 3D scenes, making it suitable for applications such as animation, virtual reality, and interactive 3D content creation [5]",[5] ARAP-GS  Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing  with Diffusion Prior
Uncertainty estimation in 3D Gaussian Splatting (3DGS) is a critical aspect that enhances the reliability and interpretability of 3D reconstructions [15],[15] AAA-Gaussians  Anti-Aliased and Artifact-Free 3D Gaussian Rendering
"Unlike traditional methods that often treat uncertainty as a scalar value, 3DGS leverages its explicit representation of 3D Gaussians to model uncertainty in a more nuanced manner [2]",[2] View-Dependent Uncertainty Estimation of 3D Gaussian Splatting
The use of spherical harmonics for uncertainty estimation in 3DGS builds upon the existing view-dependent color representation of Gaussians [2],[2] View-Dependent Uncertainty Estimation of 3D Gaussian Splatting
"Each Gaussian in the 3DGS model is characterized by its position, scale, rotation, color, and opacity [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"Overall, the integration of spherical harmonics for uncertainty estimation in 3DGS represents a significant step forward in enhancing the robustness and interpretability of 3D scene representations [2]",[2] View-Dependent Uncertainty Estimation of 3D Gaussian Splatting
Precomputation for efficient training is a critical strategy in 3D Gaussian Splatting (3DGS) to manage the computational demands of large-scale scenes [10],[10] EDGS  Eliminating Densification for Efficient Convergence of 3DGS
"Moreover, this approach ensures that the spatial relationships between Gaussians remain consistent throughout the training process, which is crucial for maintaining the structural integrity of the 3D scene representation [15]",[15] AAA-Gaussians  Anti-Aliased and Artifact-Free 3D Gaussian Rendering
"By precomputing and storing the neighborhood relationships, we can distribute the computational load more evenly across multiple GPUs, ensuring that each GPU processes a balanced subset of the scene [16]",[16] BlockGaussian  Efficient Large-Scale Scene Novel View Synthesis via  Adaptive Block-Based Gaussian S
The direct initialization strategy in 3D Gaussian Splatting (3DGS) fundamentally alters the traditional incremental refinement process by precomputing a dense set of 3D Gaussians from 2D correspondences across multiple input views [10],[10] EDGS  Eliminating Densification for Efficient Convergence of 3DGS
This approach leverages the known viewing rays for each correspondence pixel and the camera poses to triangulate the initial positions of the Gaussians [10],[10] EDGS  Eliminating Densification for Efficient Convergence of 3DGS
"The direct initialization strategy thus provides a more principled and efficient approach to 3D scene representation, making it a valuable advancement in the field of 3D Gaussian Splatting [10]",[10] EDGS  Eliminating Densification for Efficient Convergence of 3DGS
Gaussian-Enhanced Surfels (GESs) represent a significant advancement in the field of 3D scene representation and novel view synthesis [14],[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
"GESs combine the strengths of surfels and Gaussian primitives to achieve high-quality, real-time rendering [14]",[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
"These Gaussian primitives are defined by a set of parameters, including position, scale, rotation, and opacity, allowing them to model fine details and smooth transitions in the scene [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"The coarse-to-fine approach ensures that the optimization process is efficient and robust, leading to a high-quality GES representation that can be used for real-time rendering and novel view synthesis [14]",[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
Opacity modulation and Hessian pruning are critical techniques in enhancing the efficiency and visual fidelity of 3D Gaussian Splatting (3DGS) models [10],[10] EDGS  Eliminating Densification for Efficient Convergence of 3DGS
"By introducing an opacity modulating parameter, the model can gradually evolve translucent surfels into opaque ones, allowing for smoother transitions and more accurate representation of surfaces [14]",[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
"When the opacity parameter is below 1, the surfel remains translucent with a Gaussian-distributed opacity, which helps in capturing subtle color variations and gradients [14]",[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
"As the parameter increases, the surfel becomes more opaque from the center outward, ensuring that the color-based gradients are effectively propagated during optimization [14]",[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
"By leveraging a hash grid, the system can efficiently store and retrieve directional information, which is crucial for accurate color decoding from various perspectives [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"The hash grid encodes the view direction vector, replacing the traditional MLP input, thereby enhancing the precision of view-dependent color decoding [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"This approach not only improves the accuracy of color representation but also addresses the challenge of smoothing gradients across rendered pixels, which can lead to better reconstruction of fine details and color variations in the scene [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"Traditional methods, such as rasterization and sequential ray tracing, often struggle with accurately and efficiently rendering multiple layers of transparent objects [17]",[17] Stochastic Ray Tracing of 3D Transparent Gaussians
"The TransparentGS framework is a significant advancement in the field of 3D Gaussian Splatting (3DGS), specifically designed to handle the challenges posed by transparent objects [18]",[18] TSGS  Improving Gaussian Splatting for Transparent Surface  Reconstruction via Normal and De-lightin
"Traditional 3DGS methods, while effective for opaque and reflective surfaces, struggle with transparent materials due to their reliance on visual appearance optimization, which often leads to inaccuracies in geometric representation [18]",[18] TSGS  Improving Gaussian Splatting for Transparent Surface  Reconstruction via Normal and De-lightin
The framework achieves this by modifying the opacity of Gaussian primitives to better represent transparent surfaces while maintaining the integrity of the underlying 3D structure [18],[18] TSGS  Improving Gaussian Splatting for Transparent Surface  Reconstruction via Normal and De-lightin
"In TransparentGS, the key innovation lies in the stochastic ray tracing method, which efficiently renders large sets of semi-transparent primitives [17]",[17] Stochastic Ray Tracing of 3D Transparent Gaussians
"Unlike traditional methods that process all ray-Gaussian intersections sequentially, TransparentGS traverses the acceleration structure only once per ray, accepting and shading a single intersection [17]",[17] Stochastic Ray Tracing of 3D Transparent Gaussians
"The framework also employs an opacity modulating parameter during optimization, which gradually evolves translucent surfels into opaque ones, ensuring that the geometry is optimized and stabilized over time [14]",[14] When Gaussian Meets Surfel  Ultra-fast High-fidelity Radiance Field  Rendering
"Moreover, the use of Gaussian light field probes (GaussProbes) further enhances the realism by capturing the local light field around transparent objects, thereby providing accurate lighting information for secondary ray effects such as shadows and reflections [19]",[19] TransparentGS  Fast Inverse Rendering of Transparent Objects with  Gaussians
"By addressing the limitations of previous methods in handling complex lighting and material properties, RGS-DR sets a new standard for the rendering of reflective and transparent surfaces in 3D scenes [19]",[19] TransparentGS  Fast Inverse Rendering of Transparent Objects with  Gaussians
Stochastic ray tracing for transparency addresses the challenges of efficiently and accurately rendering 3D clouds of transparent primitives [17],[17] Stochastic Ray Tracing of 3D Transparent Gaussians
"By analyzing the variance of color gradients, this technique pinpoints regions with high color variation but low gradient variation in position, indicating areas where the Gaussian primitives need to be denser [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"Furthermore, the stochastic ray tracing method can be extended to shade multiple intersections within a single traversal, providing a balance between computational efficiency and rendering quality [17]",[17] Stochastic Ray Tracing of 3D Transparent Gaussians
"The simplicity and effectiveness of this approach have enabled its integration into commercial Monte Carlo renderers, facilitating seamless rendering of 3D Gaussians alongside conventional 3D assets [17]",[17] Stochastic Ray Tracing of 3D Transparent Gaussians
3D Gabor Splatting (3DGS) builds upon the foundational concept of 3D Gaussian Splatting by introducing the Gabor kernel to enhance the color variation and detail in the reconstructed 3D scenes [3],[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"By integrating the Gabor kernel into the 3D Gaussian primitives, 3D Gabor Splatting can efficiently model high-frequency color variations, which are essential for realistic rendering of materials such as textiles and other surfaces with fine textures [20]",[20] 3D Gabor Splatting  Reconstruction of High-frequency Surface Texture  using Gabor Noise
"In traditional 3D Gaussian Splatting, each Gaussian primitive is defined by a set of parameters including position, scale, rotation, opacity, and color [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"However, this approach often struggles to capture high-frequency color variations, leading to a loss of detail in the final render. 3D Gabor Splatting addresses this limitation by augmenting each Gaussian primitive with a Gabor kernel, allowing each primitive to represent a wider range of colors and textures [20]",[20] 3D Gabor Splatting  Reconstruction of High-frequency Surface Texture  using Gabor Noise
"Additionally, the method leverages standard triangle-mesh acceleration structures for efficient Gaussian ray tracing, making it suitable for real-time rendering applications [17]",[17] Stochastic Ray Tracing of 3D Transparent Gaussians
The resulting 3D Gabor Splatting method not only improves the visual fidelity of the rendered scenes but also maintains the computational efficiency required for practical applications in computer graphics and vision [20],[20] 3D Gabor Splatting  Reconstruction of High-frequency Surface Texture  using Gabor Noise
"Spatially-Varying Gaussian Representation (SVG) is a significant advancement in 3D scene representation, extending the capabilities of traditional Constant Gaussian models [21]",[21] SVG-IR  Spatially-Varying Gaussian Splatting for Inverse Rendering
"Unlike Constant Gaussians, which assume uniform material and normal properties across the entire primitive, SVGs allow for these properties to vary spatially within a single Gaussian [21]",[21] SVG-IR  Spatially-Varying Gaussian Splatting for Inverse Rendering
"Overall, the Spatially-Varying Gaussian Representation offers a powerful tool for achieving high-fidelity 3D scene reconstruction and novel view synthesis, bridging the gap between theoretical models and practical applications [12]",[12] VGNC  Reducing the Overfitting of Sparse-view 3DGS via Validation-guided  Gaussian Number Control
Variance-guided densification is a technique designed to enhance the quality of 3D Gaussian splatting (3DGS) reconstructions by strategically increasing the density of Gaussians in areas that require more detail [22],[22] Novel Demonstration Generation with Gaussian Splatting Enables Robust  One-Shot Manipulation
"This approach is particularly effective in addressing the shortcomings of traditional methods that rely solely on position gradients, which often fail to capture the fine details and variations in color that are crucial for high-quality reconstructions [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"To implement variance-guided densification, a maximum-weight window aggregation algorithm is used to analyze the color gradients in the scene [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"This algorithm efficiently identifies the regions with high color variance and low position gradient variation, allowing for targeted densification of the Gaussian primitives [3]",[3] Metamon-GS  Enhancing Representability with Variance-Guided  Densification and Light Encoding
"SEGA, a pioneering method for single-image-based 3D face avatar creation, addresses the limitations of existing approaches by integrating 2D and 3D priors to achieve high-quality, drivable avatars [23]",[23] SEGA  Drivable 3D Gaussian Head Avatar from a Single Image
The method leverages a pre-trained network on large-scale 2D face datasets to encode identity information from a single input image [23],[23] SEGA  Drivable 3D Gaussian Head Avatar from a Single Image
"The method's ability to create high-quality avatars from a single image opens up new possibilities for applications in virtual reality (VR), augmented reality (AR), and digital entertainment, where rapid and personalized avatar creation is crucial [24]",[24] GSAC  Leveraging Gaussian Splatting for Photorealistic Avatar Creation  with Unity Integration
"SEGA's robustness and efficiency make it a promising solution for integrating realistic 3D face avatars into interactive environments, enhancing user engagement and immersion [23]",[23] SEGA  Drivable 3D Gaussian Head Avatar from a Single Image
"Monocular video-based avatar creation represents a significant advancement in the field of 3D reconstruction and novel view synthesis, particularly in scenarios where multi-view data is not readily available [23]",[23] SEGA  Drivable 3D Gaussian Head Avatar from a Single Image
"This capability is crucial for applications such as virtual reality (VR), augmented reality (AR), and telepresence, where the ability to create realistic avatars from everyday video recordings can greatly enhance user experience and interaction [24]",[24] GSAC  Leveraging Gaussian Splatting for Photorealistic Avatar Creation  with Unity Integration
Recent methods have addressed this by integrating 3D Gaussian Splatting (3DGS) with continuous-time trajectory optimization [10],[10] EDGS  Eliminating Densification for Efficient Convergence of 3DGS
"Additionally, the use of a camera response function (CRF) module allows for the conversion of accumulated irradiance into high dynamic range (HDR) images, further enhancing the quality of the reconstructed scenes [25]",[25] CasualHDRSplat  Robust High Dynamic Range 3D Gaussian Splatting from  Casually Captured Videos
"These methods enable the creation of photorealistic avatars and scenes from monocular videos, even in challenging conditions such as low light and high-speed motion [23]",[23] SEGA  Drivable 3D Gaussian Head Avatar from a Single Image
"This module captures fine-grained changes in facial geometry, such as skin deformations and shadows, that result from hand contact [26]",[26] InteractAvatar  Modeling Hand-Face Interaction in Photorealistic Avatars  with Deformable Gaussians
"This level of detail is crucial for applications where the realism of the avatar is paramount, such as in social VR environments where nonverbal communication cues play a critical role in user engagement and interaction [26]",[26] InteractAvatar  Modeling Hand-Face Interaction in Photorealistic Avatars  with Deformable Gaussians
"To achieve these results, InteractAvatar employs a sophisticated optimization framework that jointly tracks camera poses and human poses, while also constructing a consistent dense scene map with both geometric and appearance information [27]",[27] ODHSR  Online Dense 3D Reconstruction of Humans and Scenes from  Monocular Videos
"The method uses 3D Gaussians in canonical space, guided by SMPL-based deformations, to model the human avatar [27]",[27] ODHSR  Online Dense 3D Reconstruction of Humans and Scenes from  Monocular Videos
"Through extensive experiments, InteractAvatar has demonstrated superior performance in both novel view synthesis and self-reenactment tasks, setting a new standard for the realistic modeling of hand-face interactions in digital avatars [26]",[26] InteractAvatar  Modeling Hand-Face Interaction in Photorealistic Avatars  with Deformable Gaussians
"In the context of motion deblurring, the integration of 3D Gaussian Splatting (3DGS) into the deblurring process, as proposed in the MoBGS method, represents a significant advancement [15]",[15] AAA-Gaussians  Anti-Aliased and Artifact-Free 3D Gaussian Rendering
"MoBGS addresses the inherent challenges of motion blur and varying image brightness by incorporating a unified differentiable rendering framework that models the physical imaging process, including camera motion and exposure time [25]",[25] CasualHDRSplat  Robust High Dynamic Range 3D Gaussian Splatting from  Casually Captured Videos
"This approach allows for the joint optimization of the camera trajectory, color response function (CRF), and exposure time, effectively decoupling the effects of camera motion and irradiance accumulation [25]",[25] CasualHDRSplat  Robust High Dynamic Range 3D Gaussian Splatting from  Casually Captured Videos
"By accurately predicting latent camera poses and estimating exposure timestamps, MoBGS can simulate the physical formation of motion blur and correct it during the reconstruction process [28]",[28] MoBGS  Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry  Monocular Video
Empirical evaluations on the Stereo Blur dataset and real-world video sequences have demonstrated the superiority of MoBGS over existing state-of-the-art methods in terms of deblurring quality and novel view synthesis (NVS) [28],[28] MoBGS  Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry  Monocular Video
"The method's ability to handle diverse and complex motion patterns, coupled with its efficiency in processing monocular videos, makes it a promising solution for applications requiring high-quality, real-time deblurring and NVS [28]",[28] MoBGS  Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry  Monocular Video
"The method optimizes Gaussian parameters and camera poses simultaneously, ensuring that the reconstructed 3D scene is both accurate and free from motion blur [29]",[29] EBAD-Gaussian  Event-driven Bundle Adjusted Deblur Gaussian Splatting
"To achieve this, EBAD-Gaussian introduces a motion blur loss function that penalizes inconsistencies between the reconstructed scene and the observed events [29]",[29] EBAD-Gaussian  Event-driven Bundle Adjusted Deblur Gaussian Splatting
"The use of event data not only helps in reducing motion blur but also improves the reconstruction of underexposed regions, making EBAD-Gaussian a versatile solution for event-driven deblurring in a wide range of applications, from robotics to augmented reality [29]",[29] EBAD-Gaussian  Event-driven Bundle Adjusted Deblur Gaussian Splatting
"ODHSR (Online Dense Human Scene Reconstruction) represents a significant advancement in the field of real-time Simultaneous Localization and Mapping (SLAM) by integrating camera tracking, human pose estimation, and dense photorealistic reconstruction into a unified framework [27]",[27] ODHSR  Online Dense 3D Reconstruction of Humans and Scenes from  Monocular Videos
"The system leverages a continuous-time trajectory model to represent camera motion, allowing for joint optimization of camera poses and exposure times, which is crucial for handling dynamic scenes and ensuring geometric consistency in the reconstructed models [25]",[25] CasualHDRSplat  Robust High Dynamic Range 3D Gaussian Splatting from  Casually Captured Videos
"To address the limitations of traditional 3D Gaussian Splatting (3DGS) methods, particularly in low-light and high-speed scenarios, ODHSR introduces a novel framework that fuses event streams with RGB data [29]",[29] EBAD-Gaussian  Event-driven Bundle Adjusted Deblur Gaussian Splatting
"The motion blur loss incorporated in the framework helps in refining camera poses and Gaussian parameters, leading to more accurate and detailed reconstructions [29]",[29] EBAD-Gaussian  Event-driven Bundle Adjusted Deblur Gaussian Splatting
"By optimizing these parameters within the exposure time, ODHSR achieves superior results in global human pose estimation and camera tracking, setting a new benchmark for real-time SLAM systems [27]",[27] ODHSR  Online Dense 3D Reconstruction of Humans and Scenes from  Monocular Videos
"RoboSplat represents a significant advancement in the development of visuomotor policies for robotic manipulation, addressing the critical issue of data scarcity and domain shift between training and deployment environments [22]",[22] Novel Demonstration Generation with Gaussian Splatting Enables Robust  One-Shot Manipulation
"By segmenting 3D Gaussians of different scene components using off-the-shelf segmentation models and the robot's URDF, RoboSplat can generate a diverse set of training data from a single expert trajectory [22]",[22] Novel Demonstration Generation with Gaussian Splatting Enables Robust  One-Shot Manipulation
"The core innovation of RoboSplat lies in its ability to simulate a wide range of visual domains, including variations in lighting, texture, and object configurations, which are crucial for the robustness of visuomotor policies [22]",[22] Novel Demonstration Generation with Gaussian Splatting Enables Robust  One-Shot Manipulation
"To address these limitations, the Bimanual Interaction 3D Gaussian Splatting (BIGS) pipeline was introduced [30]",[30] BIGS  Bimanual Category-agnostic Interaction Reconstruction from  Monocular Videos via 3D Gaussian S
BIGS leverages 3D Gaussian splatting to build detailed 3D models of both hands and an unknown object from monocular video inputs [30],[30] BIGS  Bimanual Category-agnostic Interaction Reconstruction from  Monocular Videos via 3D Gaussian S
"The use of 3D Gaussian splatting enables the pipeline to handle the high variability and dynamic nature of hand-object interactions, making it a powerful tool for applications such as virtual reality, robotics, and human-computer interaction [30]",[30] BIGS  Bimanual Category-agnostic Interaction Reconstruction from  Monocular Videos via 3D Gaussian S
"CasualHDRSplat is a pioneering one-stage method that addresses the challenges of 3D HDR reconstruction by integrating the physical imaging model with camera motion, exposure time, and camera response function (CRF) in a unified framework [25]",[25] CasualHDRSplat  Robust High Dynamic Range 3D Gaussian Splatting from  Casually Captured Videos
"By jointly optimizing these parameters, CasualHDRSplat enhances the robustness and flexibility of the reconstruction process, enabling it to handle dynamic scenes with varying lighting conditions and complex camera motions [25]",[25] CasualHDRSplat  Robust High Dynamic Range 3D Gaussian Splatting from  Casually Captured Videos
"Furthermore, CasualHDRSplat employs a 3D Gaussian Splatting (3DGS) representation to achieve efficient and high-fidelity 3D reconstruction [7]",[7] CAGE-GS  High-fidelity Cage Based 3D Gaussian Splatting Deformation
"The 3DGS model represents the scene using a set of Gaussian distributions, which can be optimized directly and efficiently [31]",[31] Volume Encoding Gaussians  Transfer Function-Agnostic 3D Gaussians for  Volume Rendering
"By combining the 3DGS model with the unified imaging model, CasualHDRSplat can reconstruct detailed 3D HDR scenes from monocular RGB videos, even under challenging conditions such as fast camera motion and low light [25]",[25] CasualHDRSplat  Robust High Dynamic Range 3D Gaussian Splatting from  Casually Captured Videos
